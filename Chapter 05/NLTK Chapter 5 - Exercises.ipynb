{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 5\n",
    "\n",
    "## Categorizing and Tagging Words\n",
    "\n",
    "*The html version of this chapter in the NLTK book is available [here](https://www.nltk.org/book/ch05.html#exercises \"Ch05 Exercises\").*\n",
    "\n",
    "### 5.10   Exercises\n",
    "\n",
    "##### 1.\n",
    "\n",
    "☼ Search the web for \"spoof newspaper headlines\", to find such gems as: *British Left Waffles on Falkland Islands*, and *Juvenile Court to Try Shooting Defendant*. Manually tag these headlines to see if knowledge of the part-of-speech tags removes the ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No, the ambiguity is not necessarily removed.  For example, in __\"Drunk Gets Nine Months in Violin Case\"__, the ambiguity concerns the two senses of the word \"Case\", which are both nouns.  Likewise with the headline __\"Miners Refuse to Work after Death\"__, where the two senses of \"Death\" are also nouns.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.\n",
    "\n",
    "☼ Working with someone else, take turns to pick a word that can be either a noun or a verb (e.g. *contest*); the opponent has to predict which one is likely to be the most frequent in the Brown corpus; check the opponent's prediction, and tally the score over several turns.\n",
    "\n",
    "*I'm just playing against myself.  I took a list of words from [this page](https://www.businessenglishresources.com/learn-english-for-business/teachers-section/mini-lessons/pronunciation-lessons-pronunciation-changes-in-words-that-are-both-nouns-and-verbs/ \"words that are both nouns and verbs\"), and manually sorted them into two lists: one for words I thought were more likely to be nouns, and one for words I thought were more likely to be verbs.  I then devised code which programmatically check this for me:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 19), ('VB', 16)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btw = nltk.corpus.brown.tagged_words()\n",
    "cfd = nltk.ConditionalFreqDist(btw)\n",
    "likely_nouns = [\"conduct\", \"combat\", \"conflict\", \"contest\", \"contract\", \n",
    "                \"impact\", \"insult\", \"object\", \"present\", \"progress\", \"project\",\n",
    "                \"rebel\", \"refill\", \"refund\", \"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([cfd[ln].most_common()[0][0] == 'NN' for ln in likely_nouns])/len(likely_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('present', [('JJ', 220), ('RB', 63), ('NN', 44), ('VB', 39), ('AP', 4)]),\n",
       " ('refill', [('VB', 1)])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ln, cfd[ln].most_common()) for ln in likely_nouns if cfd[ln].most_common()[0][0] != 'NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective\n",
      "    ecent over-all possible hard-fought favorable hard meager fit such\n",
      "    widespread outmoded inadequate ambiguous grand clerical effective\n",
      "    orderly federal foster general proportionate ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.brown_tagset('JJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I neglected to consider that 'present' can also be an adjective.  I was also suprised that 'refill' was only in the corpus once, which may be an artifact of the corpus's age, as soft drink fountains weren't as ubiquitous 50 years ago.*\n",
    "\n",
    "*Trying the same with the words I suspect are more common as verbs:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_meaning = [\"conduct\", \"attribute\", \"combat\", \"conflict\", \"contest\", \n",
    "                \"contract\", \"decrease\", \"escort\", \"impact\", \"increase\", \n",
    "                \"insult\", \"object\", \"permit\", \"present\", \"proceed\", \"progress\",\n",
    "                \"project\", \"rebel\", \"refill\", \"refund\", \"reject\", \"repeat\", \n",
    "                \"subject\", \"suspect\"]\n",
    "likely_verbs = [dm for dm in dual_meaning if dm not in likely_nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([cfd[lv].most_common()[0][0] == 'VB' for lv in likely_verbs])/len(likely_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('attribute', [('NN', 4), ('VB', 2)]),\n",
       " ('escort', [('NN', 5), ('VB', 4)]),\n",
       " ('increase', [('NN', 112), ('VB', 81), ('VB-HL', 1)])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(lv, cfd[lv].most_common()) for lv in likely_verbs if cfd[lv].most_common()[0][0] != 'VB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. \n",
    "\n",
    "☼ Tokenize and tag the following sentence: *They wind back the clock, while we chase after the wind.* What different pronunciations and parts of speech are involved?\n",
    "\n",
    "*Using the universal tagset.  A good description thereof can be found [here](https://universaldependencies.org/u/pos/ \"Universal Tagset\"):*\n",
    "\n",
    "They|PRON wind|VERB back|ADP the|DET clock|NOUN ,|PUNCT while|CCONJ we|PRON chase|VERB after|ADP the|DET wind|NOUN .|PUNCT\n",
    "\n",
    "*The only homonyms that could be pronounced differently are wind|VERB __/ˈwaɪnd/__ and wind|NOUN __/ˈwɪnd/__.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. \n",
    "\n",
    "☼ Review the mappings in [3.1](https://www.nltk.org/book/ch05.html#tab-linguistic-objects). Discuss any other examples of mappings you can think of. What type of information do they map from and to?\n",
    "\n",
    "*A phone book maps from names to phone numbers;  A map maps from GPS coordinates to a physical location;  A schedule maps from times to events; etc...*\n",
    "\n",
    "#### 5.\n",
    "\n",
    "☼ Using the Python interpreter in interactive mode, experiment with the dictionary examples in this chapter. Create a dictionary `d`, and add some entries. What happens if you try to access a non-existent entry, e.g. `d['xyz']`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'123': 'easy as', 'DoReMi': 'simple as', 'abc': 'baby, you and me girl'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Looking up a non-existent key will throw an error:*\n",
    "\n",
    "```\n",
    "d['xyz']\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "<ipython-input-27-eff1decdc6c9> in <module>\n",
    "----> 1 d['xyz']\n",
    "\n",
    "KeyError: 'xyz'\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.\n",
    "\n",
    "☼ Try deleting an element from a dictionary `d`, using the syntax `del d['abc']`. Check that the item was deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baby, you and me girl'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['abc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d['abc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "d['abc']\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "<ipython-input-29-d1565fe7f927> in <module>\n",
    "----> 1 d['abc']\n",
    "\n",
    "KeyError: 'abc'\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.\n",
    "\n",
    "☼ Create two dictionaries, `d1` and `d2`, and add some entries to each. Now issue the command `d1.update(d2)`. What did this do? What might it be useful for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {'do': 'a deer, a female deer', 're': 'a drop of golden sun'}\n",
    "d2 = {'mi': 'a name I call myself', 'fa': 'a long, long way to run'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do': 'a deer, a female deer',\n",
       " 're': 'a drop of golden sun',\n",
       " 'mi': 'a name I call myself',\n",
       " 'fa': 'a long, long way to run'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.update(d2)\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It concatenated the dictionaries.  It's useful for updating dictionaries without having to redefine them.*\n",
    "\n",
    "##### 8. \n",
    "\n",
    "☼ Create a dictionary `e`, to represent a single lexical entry for some word of your choice. Define keys like `headword`, `part-of-speech`, `sense`, and `example`, and assign them suitable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winklepicker\n",
    "\n",
    "e = {'headword': 'A style of boot with a severely pointed toe, fashionable in the 1950s.',\n",
    "  'part-of-speech': 'Noun', \n",
    "  'sense': 'type of footwear', \n",
    "  'example': 'Winklepickers were very popular among mods in the 60s.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headword': 'A style of boot with a severely pointed toe, fashionable in the 1950s.',\n",
       " 'part-of-speech': 'Noun',\n",
       " 'sense': 'type of footwear',\n",
       " 'example': 'Winklepickers were very popular among mods in the 60s.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. \n",
    "\n",
    "☼ Satisfy yourself that there are restrictions on the distribution of *go* and *went*, in the sense that they cannot be freely interchanged in the kinds of contexts illustrated in ([3d](https://www.nltk.org/book/ch05.html#ex-go)) in [7](https://www.nltk.org/book/ch05.html#sec-how-to-determine-the-category-of-a-word).\n",
    "\n",
    "<i>'Go' cannot be replaced by 'went' when used in the imperative mood (e.g., \"*Please went.\", or when referring to future events (e.g., \"*They will went to the festival tomorrow.\").  'Went' cannot be replaced by 'go' for the 3rd person: \"*He go to school in the morning.\"</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. \n",
    "\n",
    "☼ Train a unigram tagger and run it on some new text. Observe that some words are not assigned a tag. Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "unigram_tagger = nltk.UnigramTagger(brown.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " (\"shouldn't\", 'MD*'),\n",
       " ('be', 'BE'),\n",
       " ('too', 'QL'),\n",
       " ('difficult', 'JJ')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"this shouldn't be too difficult\"\n",
    "unigram_tagger.tag(test.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'BE'),\n",
       " ('a', 'AT'),\n",
       " ('bit', 'NN'),\n",
       " ('more', 'QL'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('challenge,', None),\n",
       " ('as', 'CS'),\n",
       " ('they', 'PPSS'),\n",
       " (\"didn't\", 'DOD*'),\n",
       " ('have', 'HV'),\n",
       " ('blogs', None),\n",
       " ('when', 'WRB'),\n",
       " ('the', 'AT'),\n",
       " ('corpus', 'NN'),\n",
       " ('was', 'BEDZ'),\n",
       " ('compiled', 'VBN')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = \"\"\"\n",
    "        this should be a bit more of a challenge, \n",
    "        as they didn't have blogs when the corpus\n",
    "        was compiled\n",
    "        \"\"\"\n",
    "unigram_tagger.tag(test2.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I expected that the word 'blog' would be tagged with `None`, as I was certain it wouldn't have appeared in the Brown Corpus.  But I was surprised to see that 'challenge' was also tagged with `None`.  I tried to do a little investigating into this, but wasn't able to come up with a satisfactory answer.  I suspected it may have had something to do with the fact that challenge can be either a noun or a verb, but other words with this quality don't seem to be tagged with `None`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 21, 'VB': 14})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words())\n",
    "cfd['challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 5, 'VB': 4})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd['escort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'WDT'),\n",
       " ('about', 'IN'),\n",
       " ('the', 'AT'),\n",
       " ('word', 'NN'),\n",
       " ('escort', 'NN')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = 'what about the word escort'\n",
    "unigram_tagger.tag(test3.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11.\n",
    "\n",
    "☼ Learn about the affix tagger (type `help(nltk.AffixTagger)`). Train an affix tagger and run it on some new text. Experiment with different settings for the affix length and the minimum word length. Discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AffixTagger in module nltk.tag.sequential:\n",
      "\n",
      "class AffixTagger(ContextTagger)\n",
      " |  AffixTagger(train=None, model=None, affix_length=-3, min_stem_length=2, backoff=None, cutoff=0, verbose=False)\n",
      " |  \n",
      " |  A tagger that chooses a token's tag based on a leading or trailing\n",
      " |  substring of its word string.  (It is important to note that these\n",
      " |  substrings are not necessarily \"true\" morphological affixes).  In\n",
      " |  particular, a fixed-length substring of the word is looked up in a\n",
      " |  table, and the corresponding tag is returned.  Affix taggers are\n",
      " |  typically constructed by training them on a tagged corpus.\n",
      " |  \n",
      " |  Construct a new affix tagger.\n",
      " |  \n",
      " |  :param affix_length: The length of the affixes that should be\n",
      " |      considered during training and tagging.  Use negative\n",
      " |      numbers for suffixes.\n",
      " |  :param min_stem_length: Any words whose length is less than\n",
      " |      min_stem_length+abs(affix_length) will be assigned a\n",
      " |      tag of None by this tagger.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AffixTagger\n",
      " |      ContextTagger\n",
      " |      SequentialBackoffTagger\n",
      " |      nltk.tag.api.TaggerI\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, train=None, model=None, affix_length=-3, min_stem_length=2, backoff=None, cutoff=0, verbose=False)\n",
      " |      :param context_to_tag: A dictionary mapping contexts to tags.\n",
      " |      :param backoff: The backoff tagger that should be used for this tagger.\n",
      " |  \n",
      " |  context(self, tokens, index, history)\n",
      " |      :return: the context that should be used to look up the tag\n",
      " |          for the specified token; or None if the specified token\n",
      " |          should not be handled by this tagger.\n",
      " |      :rtype: (hashable)\n",
      " |  \n",
      " |  encode_json_obj(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  decode_json_obj(obj) from abc.ABCMeta\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  json_tag = 'nltk.tag.sequential.AffixTagger'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ContextTagger:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  choose_tag(self, tokens, index, history)\n",
      " |      Decide which tag should be used for the specified token, and\n",
      " |      return that tag.  If this tagger is unable to determine a tag\n",
      " |      for the specified token, return None -- do not consult\n",
      " |      the backoff tagger.  This method should be overridden by\n",
      " |      subclasses of SequentialBackoffTagger.\n",
      " |      \n",
      " |      :rtype: str\n",
      " |      :type tokens: list\n",
      " |      :param tokens: The list of words that are being tagged.\n",
      " |      :type index: int\n",
      " |      :param index: The index of the word whose tag should be\n",
      " |          returned.\n",
      " |      :type history: list(str)\n",
      " |      :param history: A list of the tags for all words before *index*.\n",
      " |  \n",
      " |  size(self)\n",
      " |      :return: The number of entries in the table used by this\n",
      " |          tagger to map from contexts to tags.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from SequentialBackoffTagger:\n",
      " |  \n",
      " |  tag(self, tokens)\n",
      " |      Determine the most appropriate tag sequence for the given\n",
      " |      token sequence, and return a corresponding list of tagged\n",
      " |      tokens.  A tagged token is encoded as a tuple ``(token, tag)``.\n",
      " |      \n",
      " |      :rtype: list(tuple(str, str))\n",
      " |  \n",
      " |  tag_one(self, tokens, index, history)\n",
      " |      Determine an appropriate tag for the specified token, and\n",
      " |      return that tag.  If this tagger is unable to determine a tag\n",
      " |      for the specified token, then its backoff tagger is consulted.\n",
      " |      \n",
      " |      :rtype: str\n",
      " |      :type tokens: list\n",
      " |      :param tokens: The list of words that are being tagged.\n",
      " |      :type index: int\n",
      " |      :param index: The index of the word whose tag should be\n",
      " |          returned.\n",
      " |      :type history: list(str)\n",
      " |      :param history: A list of the tags for all words before *index*.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SequentialBackoffTagger:\n",
      " |  \n",
      " |  backoff\n",
      " |      The backoff tagger for this tagger.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.tag.api.TaggerI:\n",
      " |  \n",
      " |  evaluate(self, gold)\n",
      " |      Score the accuracy of the tagger against the gold standard.\n",
      " |      Strip the tags from the gold standard text, retag it using\n",
      " |      the tagger, then compute the accuracy score.\n",
      " |      \n",
      " |      :type gold: list(list(tuple(str, str)))\n",
      " |      :param gold: The list of tagged sentences to score the tagger on.\n",
      " |      :rtype: float\n",
      " |  \n",
      " |  tag_sents(self, sentences)\n",
      " |      Apply ``self.tag()`` to each element of *sentences*.  I.e.:\n",
      " |      \n",
      " |          return [self.tag(sent) for sent in sentences]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.tag.api.TaggerI:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.AffixTagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creating and calling a number of taggers will soon create an illegible mess, so I'm adapting some code from earlier this chapter to make a graph of affix taggers, using affix lengths from -5 to 5:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "brown_sents = brown.sents(categories = 'news')\n",
    "\n",
    "def performance(affix_size):\n",
    "    affix_tagger = nltk.AffixTagger(brown_tagged_sents, affix_length = affix_size)\n",
    "    return affix_tagger.evaluate(brown_tagged_sents)\n",
    "\n",
    "def display():\n",
    "    sizes = np.arange(-5, 6)\n",
    "    perfs = [performance(size) for size in sizes]\n",
    "    plt.plot(sizes, perfs, '-bo')\n",
    "    plt.title('Affix Tagger Performance with Varying Affix Length')\n",
    "    plt.xlabel('Affix Length')\n",
    "    plt.ylabel('Performance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As you can see, the most accurate length by far is 0, suggesting that the affix tagger is not very effective (at least in English).  If we were to use it, an affix length of -2 appears to be slightly more effective than other lengths.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. \n",
    "\n",
    "☼ Train a bigram tagger with no backoff tagger, and run it on some of the training data. Next, run it on some new data. What happens to the performance of the tagger? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884137382485832"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.evaluate(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10206319146815508"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger.evaluate(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It drops precipitously when it sees new data.  As was covered in the chapter, bigrams depend entirely on the tag of the first word in the bigram.  If the tag for the first word is `None`, then the tags for all subsequent words will also be `None`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13.\n",
    "\n",
    "☼ We can use a dictionary to specify the values to be substituted into a formatting string. Read Python's library documentation for formatting strings  and use this method to display today's date in two different formats.\n",
    "\n",
    "*The link in the book is dead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European style: Wednesday, 06.11.2019\n",
      "American style: Wednesday, 11/06/2019\n",
      "Asian style: Wednesday, 2019.11.06\n"
     ]
    }
   ],
   "source": [
    "date = {'month': '11', 'date': '06', 'day': 'Wednesday', 'year': '2019'}\n",
    "\n",
    "print(\"European style: {}, {}.{}.{}\".format(date['day'], date['date'], \n",
    "                                            date['month'], date['year']))\n",
    "print(\"American style: {}, {}/{}/{}\".format(date['day'], date['month'],\n",
    "                                            date['date'], date['year']))\n",
    "print(\"Asian style: {}, {}.{}.{}\".format(date['day'], date['year'],\n",
    "                                         date['month'], date['date']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14.\n",
    "\n",
    "◑ Use `sorted()` and `set()` to get a sorted list of tags used in the Brown corpus, removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", \"''\", '(', '(-HL', ')', ')-HL', '*', '*-HL', '*-NC', '*-TL', ',', ',-HL', ',-NC', ',-TL', '--', '---HL', '.', '.-HL', '.-NC', '.-TL', ':', ':-HL', ':-TL', 'ABL', 'ABN', 'ABN-HL', 'ABN-NC', 'ABN-TL', 'ABX', 'AP', 'AP$', 'AP+AP-NC', 'AP-HL', 'AP-NC', 'AP-TL', 'AT', 'AT-HL', 'AT-NC', 'AT-TL', 'AT-TL-HL', 'BE', 'BE-HL', 'BE-TL', 'BED', 'BED*', 'BED-NC', 'BEDZ', 'BEDZ*', 'BEDZ-HL', 'BEDZ-NC', 'BEG', 'BEM', 'BEM*', 'BEM-NC', 'BEN', 'BEN-TL', 'BER', 'BER*', 'BER*-NC', 'BER-HL', 'BER-NC', 'BER-TL', 'BEZ', 'BEZ*', 'BEZ-HL', 'BEZ-NC', 'BEZ-TL', 'CC', 'CC-HL', 'CC-NC', 'CC-TL', 'CC-TL-HL', 'CD', 'CD$', 'CD-HL', 'CD-NC', 'CD-TL', 'CD-TL-HL', 'CS', 'CS-HL', 'CS-NC', 'CS-TL', 'DO', 'DO*', 'DO*-HL', 'DO+PPSS', 'DO-HL', 'DO-NC', 'DO-TL', 'DOD', 'DOD*', 'DOD*-TL', 'DOD-NC', 'DOZ', 'DOZ*', 'DOZ*-TL', 'DOZ-HL', 'DOZ-TL', 'DT', 'DT$', 'DT+BEZ', 'DT+BEZ-NC', 'DT+MD', 'DT-HL', 'DT-NC', 'DT-TL', 'DTI', 'DTI-HL', 'DTI-TL', 'DTS', 'DTS+BEZ', 'DTS-HL', 'DTX', 'EX', 'EX+BEZ', 'EX+HVD', 'EX+HVZ', 'EX+MD', 'EX-HL', 'EX-NC', 'FW-*', 'FW-*-TL', 'FW-AT', 'FW-AT+NN-TL', 'FW-AT+NP-TL', 'FW-AT-HL', 'FW-AT-TL', 'FW-BE', 'FW-BER', 'FW-BEZ', 'FW-CC', 'FW-CC-TL', 'FW-CD', 'FW-CD-TL', 'FW-CS', 'FW-DT', 'FW-DT+BEZ', 'FW-DTS', 'FW-HV', 'FW-IN', 'FW-IN+AT', 'FW-IN+AT-T', 'FW-IN+AT-TL', 'FW-IN+NN', 'FW-IN+NN-TL', 'FW-IN+NP-TL', 'FW-IN-TL', 'FW-JJ', 'FW-JJ-NC', 'FW-JJ-TL', 'FW-JJR', 'FW-JJT', 'FW-NN', 'FW-NN$', 'FW-NN$-TL', 'FW-NN-NC', 'FW-NN-TL', 'FW-NN-TL-NC', 'FW-NNS', 'FW-NNS-NC', 'FW-NNS-TL', 'FW-NP', 'FW-NP-TL', 'FW-NPS', 'FW-NPS-TL', 'FW-NR', 'FW-NR-TL', 'FW-OD-NC', 'FW-OD-TL', 'FW-PN', 'FW-PP$', 'FW-PP$-NC', 'FW-PP$-TL', 'FW-PPL', 'FW-PPL+VBZ', 'FW-PPO', 'FW-PPO+IN', 'FW-PPS', 'FW-PPSS', 'FW-PPSS+HV', 'FW-QL', 'FW-RB', 'FW-RB+CC', 'FW-RB-TL', 'FW-TO+VB', 'FW-UH', 'FW-UH-NC', 'FW-UH-TL', 'FW-VB', 'FW-VB-NC', 'FW-VB-TL', 'FW-VBD', 'FW-VBD-TL', 'FW-VBG', 'FW-VBG-TL', 'FW-VBN', 'FW-VBZ', 'FW-WDT', 'FW-WPO', 'FW-WPS', 'HV', 'HV*', 'HV+TO', 'HV-HL', 'HV-NC', 'HV-TL', 'HVD', 'HVD*', 'HVD-HL', 'HVG', 'HVG-HL', 'HVN', 'HVZ', 'HVZ*', 'HVZ-NC', 'HVZ-TL', 'IN', 'IN+IN', 'IN+PPO', 'IN-HL', 'IN-NC', 'IN-TL', 'IN-TL-HL', 'JJ', 'JJ$-TL', 'JJ+JJ-NC', 'JJ-HL', 'JJ-NC', 'JJ-TL', 'JJ-TL-HL', 'JJ-TL-NC', 'JJR', 'JJR+CS', 'JJR-HL', 'JJR-NC', 'JJR-TL', 'JJS', 'JJS-HL', 'JJS-TL', 'JJT', 'JJT-HL', 'JJT-NC', 'JJT-TL', 'MD', 'MD*', 'MD*-HL', 'MD+HV', 'MD+PPSS', 'MD+TO', 'MD-HL', 'MD-NC', 'MD-TL', 'NIL', 'NN', 'NN$', 'NN$-HL', 'NN$-TL', 'NN+BEZ', 'NN+BEZ-TL', 'NN+HVD-TL', 'NN+HVZ', 'NN+HVZ-TL', 'NN+IN', 'NN+MD', 'NN+NN-NC', 'NN-HL', 'NN-NC', 'NN-TL', 'NN-TL-HL', 'NN-TL-NC', 'NNS', 'NNS$', 'NNS$-HL', 'NNS$-NC', 'NNS$-TL', 'NNS$-TL-HL', 'NNS+MD', 'NNS-HL', 'NNS-NC', 'NNS-TL', 'NNS-TL-HL', 'NNS-TL-NC', 'NP', 'NP$', 'NP$-HL', 'NP$-TL', 'NP+BEZ', 'NP+BEZ-NC', 'NP+HVZ', 'NP+HVZ-NC', 'NP+MD', 'NP-HL', 'NP-NC', 'NP-TL', 'NP-TL-HL', 'NPS', 'NPS$', 'NPS$-HL', 'NPS$-TL', 'NPS-HL', 'NPS-NC', 'NPS-TL', 'NR', 'NR$', 'NR$-TL', 'NR+MD', 'NR-HL', 'NR-NC', 'NR-TL', 'NR-TL-HL', 'NRS', 'NRS-TL', 'OD', 'OD-HL', 'OD-NC', 'OD-TL', 'PN', 'PN$', 'PN+BEZ', 'PN+HVD', 'PN+HVZ', 'PN+MD', 'PN-HL', 'PN-NC', 'PN-TL', 'PP$', 'PP$$', 'PP$-HL', 'PP$-NC', 'PP$-TL', 'PPL', 'PPL-HL', 'PPL-NC', 'PPL-TL', 'PPLS', 'PPO', 'PPO-HL', 'PPO-NC', 'PPO-TL', 'PPS', 'PPS+BEZ', 'PPS+BEZ-HL', 'PPS+BEZ-NC', 'PPS+HVD', 'PPS+HVZ', 'PPS+MD', 'PPS-HL', 'PPS-NC', 'PPS-TL', 'PPSS', 'PPSS+BEM', 'PPSS+BER', 'PPSS+BER-N', 'PPSS+BER-NC', 'PPSS+BER-TL', 'PPSS+BEZ', 'PPSS+BEZ*', 'PPSS+HV', 'PPSS+HV-TL', 'PPSS+HVD', 'PPSS+MD', 'PPSS+MD-NC', 'PPSS+VB', 'PPSS-HL', 'PPSS-NC', 'PPSS-TL', 'QL', 'QL-HL', 'QL-NC', 'QL-TL', 'QLP', 'RB', 'RB$', 'RB+BEZ', 'RB+BEZ-HL', 'RB+BEZ-NC', 'RB+CS', 'RB-HL', 'RB-NC', 'RB-TL', 'RBR', 'RBR+CS', 'RBR-NC', 'RBT', 'RN', 'RP', 'RP+IN', 'RP-HL', 'RP-NC', 'RP-TL', 'TO', 'TO+VB', 'TO-HL', 'TO-NC', 'TO-TL', 'UH', 'UH-HL', 'UH-NC', 'UH-TL', 'VB', 'VB+AT', 'VB+IN', 'VB+JJ-NC', 'VB+PPO', 'VB+RP', 'VB+TO', 'VB+VB-NC', 'VB-HL', 'VB-NC', 'VB-TL', 'VBD', 'VBD-HL', 'VBD-NC', 'VBD-TL', 'VBG', 'VBG+TO', 'VBG-HL', 'VBG-NC', 'VBG-TL', 'VBN', 'VBN+TO', 'VBN-HL', 'VBN-NC', 'VBN-TL', 'VBN-TL-HL', 'VBN-TL-NC', 'VBZ', 'VBZ-HL', 'VBZ-NC', 'VBZ-TL', 'WDT', 'WDT+BER', 'WDT+BER+PP', 'WDT+BEZ', 'WDT+BEZ-HL', 'WDT+BEZ-NC', 'WDT+BEZ-TL', 'WDT+DO+PPS', 'WDT+DOD', 'WDT+HVZ', 'WDT-HL', 'WDT-NC', 'WP$', 'WPO', 'WPO-NC', 'WPO-TL', 'WPS', 'WPS+BEZ', 'WPS+BEZ-NC', 'WPS+BEZ-TL', 'WPS+HVD', 'WPS+HVZ', 'WPS+MD', 'WPS-HL', 'WPS-NC', 'WPS-TL', 'WQL', 'WQL-TL', 'WRB', 'WRB+BER', 'WRB+BEZ', 'WRB+BEZ-TL', 'WRB+DO', 'WRB+DOD', 'WRB+DOD*', 'WRB+DOZ', 'WRB+IN', 'WRB+MD', 'WRB-HL', 'WRB-NC', 'WRB-TL', '``']"
     ]
    }
   ],
   "source": [
    "print(sorted(set([t for (_, t) in brown.tagged_words()])), end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15.\n",
    "\n",
    "Write programs to process the Brown Corpus and find answers to the following questions:\n",
    "\n",
    "* 1. Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.)\n",
    "\n",
    "* 2. Which word has the greatest number of distinct tags. What are they, and what do they represent?\n",
    "\n",
    "* 3. List tags in order of decreasing frequency. What do the 20 most frequent tags represent?\n",
    "\n",
    "* 4. Which tags are nouns most commonly found after? What do these tags represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 1:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of all singular nouns in the Brown Corpus\n",
    "\n",
    "sing_nouns = set(word.lower() for (word, tag) in \\\n",
    "                              nltk.corpus.brown.tagged_words() \\\n",
    "                              if tag == 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create set of all plural nouns in the Brown Corpus\n",
    "\n",
    "plur_nouns = set([word.lower() for (word, tag) in nltk.corpus.brown.tagged_words() if tag == 'NNS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of words that have regular plurals represented in plur_nouns\n",
    "\n",
    "cands = [n for n in sing_nouns if n + \"s\" in plur_nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get FreqDist for singular nouns\n",
    "snfd = nltk.FreqDist(word.lower() for (word, _) in nltk.corpus.brown.tagged_words() \\\n",
    "                   if word in sing_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get FreqDist for plural nouns\n",
    "pnfd = nltk.FreqDist(word.lower() for (word, _) in nltk.corpus.brown.tagged_words() \\\n",
    "                   if word in plur_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which words are more common in the plural form\n",
    "more_common_plur = [(pnfd[c + 's'], c + 's', snfd[c], c) for c in cands \\\n",
    "                    if pnfd[c + 's'] > snfd[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(943, 'years', 649, 'year'),\n",
       " (391, 'eyes', 119, 'eye'),\n",
       " (361, 'things', 331, 'thing'),\n",
       " (312, 'members', 133, 'member'),\n",
       " (291, 'means', 199, 'mean'),\n",
       " (269, 'words', 261, 'word'),\n",
       " (204, 'students', 109, 'student'),\n",
       " (193, 'minutes', 54, 'minute'),\n",
       " (188, 'months', 130, 'month'),\n",
       " (179, 'conditions', 89, 'condition'),\n",
       " (173, 'hours', 145, 'hour'),\n",
       " (169, 'miles', 42, 'mile'),\n",
       " (160, 'terms', 79, 'term'),\n",
       " (150, 'friends', 125, 'friend'),\n",
       " (138, 'methods', 137, 'method'),\n",
       " (125, 'sales', 44, 'sale'),\n",
       " (115, 'arms', 91, 'arm'),\n",
       " (106, 'leaders', 69, 'leader'),\n",
       " (103, 'elements', 52, 'element'),\n",
       " (102, 'factors', 71, 'factor')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(more_common_plur, reverse = True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 2:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# create a ConditionalFreqDist with all the words in the corpus,\n",
    "# with counts of each of their tags\n",
    "dt = nltk.ConditionalFreqDist(brown.tagged_words())\n",
    "\n",
    "# create a dictionary where the keys will be the number of distinct tags\n",
    "tags = defaultdict(list)\n",
    "for w in set(brown.words()):\n",
    "    tags[len(dt[w])].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word with the most tags\n",
    "max(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For the lower numbers, the values should be a list of distinct words.  Let's make sure that's the case:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well', 'Chinese', 'Little', 'I', 'for', 'fit', 'That', 'home', 'Long', 'out', 'as', 'it']"
     ]
    }
   ],
   "source": [
    "print(tags[7], end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Looking at the tags for 'that':*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'CS': 6419, 'DT': 1975, 'WPS': 1638, 'WPO': 135, 'QL': 54, 'DT-NC': 6, 'WPS-NC': 3, 'CS-NC': 2, 'WPS-HL': 2, 'CS-HL': 1, ...})"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['that']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding out what each of those tags means:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS: conjunction, subordinating\n",
      "    that as after whether before while like because if since for than altho\n",
      "    until so unless though providing once lest s'posin' till whereas\n",
      "    whereupon supposing tho' albeit then so's 'fore\n",
      "WPS: WH-pronoun, nominative\n",
      "    that who whoever whosoever what whatsoever\n",
      "DT: determiner/pronoun, singular\n",
      "    this each another that 'nother\n",
      "QL: qualifier, pre\n",
      "    well less very most so real as highly fundamentally even how much\n",
      "    remarkably somewhat more completely too thus ill deeply little overly\n",
      "    halfway almost impossibly far severly such ...\n",
      "WPO: WH-pronoun, accusative\n",
      "    whom that who\n",
      "No matching tags found.\n",
      "No matching tags found.\n",
      "No matching tags found.\n",
      "No matching tags found.\n",
      "No matching tags found.\n",
      "No matching tags found.\n",
      "No matching tags found.\n"
     ]
    }
   ],
   "source": [
    "for tag in dt['that']:\n",
    "    nltk.help.brown_tagset(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interestingly, over half of the tags have no description in the documentation. After a little research, I found that -NC designates a cited word; -HL designates a headline; and -TL designates a title.  If we eliminate these tags (since a conjunction in an article and a conjunction in a title are essentially the same thing), which get considerably differenct counts:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the same methods as above\n",
    "\n",
    "dt2 = nltk.ConditionalFreqDist((word, tag) for (word, tag) in \\\n",
    "                               brown.tagged_words() if not tag.endswith('TL') \\\n",
    "                               and not tag.endswith('HL') and \\\n",
    "                               not tag.endswith('NC'))\n",
    "\n",
    "tags2 = defaultdict(list)\n",
    "for w in set(brown.words()):\n",
    "    tags2[len(dt2[w])].append(w)\n",
    "\n",
    "max(tags2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well', 'that', ':', 'still', 'beat']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags2[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'CS': 6419, 'DT': 1975, 'WPS': 1638, 'WPO': 135, 'QL': 54, 'NIL': 1})"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2['that']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS: conjunction, subordinating\n",
      "    that as after whether before while like because if since for than altho\n",
      "    until so unless though providing once lest s'posin' till whereas\n",
      "    whereupon supposing tho' albeit then so's 'fore\n",
      "WPS: WH-pronoun, nominative\n",
      "    that who whoever whosoever what whatsoever\n",
      "DT: determiner/pronoun, singular\n",
      "    this each another that 'nother\n",
      "QL: qualifier, pre\n",
      "    well less very most so real as highly fundamentally even how much\n",
      "    remarkably somewhat more completely too thus ill deeply little overly\n",
      "    halfway almost impossibly far severly such ...\n",
      "WPO: WH-pronoun, accusative\n",
      "    whom that who\n",
      "No matching tags found.\n"
     ]
    }
   ],
   "source": [
    "for tag in dt2['that']:\n",
    "    nltk.help.brown_tagset(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 3:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [tags for _, tags in brown.tagged_words()]\n",
    "\n",
    "ft = nltk.FreqDist(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 152470), ('IN', 120557), ('AT', 97959), ('JJ', 64028), ('.', 60638), (',', 58156), ('NNS', 55110), ('CC', 37718), ('RB', 36464), ('NP', 34476), ('VB', 33693), ('VBN', 29186), ('VBD', 26167), ('CS', 22143), ('PPS', 18253), ('VBG', 17893), ('PP$', 16872), ('TO', 14918), ('PPSS', 13802), ('CD', 13510)]"
     ]
    }
   ],
   "source": [
    "print(ft.most_common(20), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, singular, common\n",
      "    failure burden court fire appointment awarding compensation Mayor\n",
      "    interim committee fact effect airport management surveillance jail\n",
      "    doctor intern extern night weekend duty legislation Tax Office ...\n",
      "IN: preposition\n",
      "    of in for by considering to on among at through with under into\n",
      "    regarding than since despite according per before toward against as\n",
      "    after during including between without except upon out over ...\n",
      "AT: article\n",
      "    the an no a every th' ever' ye\n",
      "JJ: adjective\n",
      "    ecent over-all possible hard-fought favorable hard meager fit such\n",
      "    widespread outmoded inadequate ambiguous grand clerical effective\n",
      "    orderly federal foster general proportionate ...\n",
      ".: sentence terminator\n",
      "    . ? ; ! :\n",
      ",: comma\n",
      "    ,\n",
      "NNS: noun, plural, common\n",
      "    irregularities presentments thanks reports voters laws legislators\n",
      "    years areas adjustments chambers $100 bonds courts sales details raises\n",
      "    sessions members congressmen votes polls calls ...\n",
      "CC: conjunction, coordinating\n",
      "    and or but plus & either neither nor yet 'n' and/or minus an'\n",
      "RB: adverb\n",
      "    only often generally also nevertheless upon together back newly no\n",
      "    likely meanwhile near then heavily there apparently yet outright fully\n",
      "    aside consistently specifically formally ever just ...\n",
      "NP: noun, singular, proper\n",
      "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
      "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
      "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
      "VB: verb, base: uninflected present, imperative or infinitive\n",
      "    investigate find act follow inure achieve reduce take remedy re-set\n",
      "    distribute realize disable feel receive continue place protect\n",
      "    eliminate elaborate work permit run enter force ...\n",
      "VBN: verb, past participle\n",
      "    conducted charged won received studied revised operated accepted\n",
      "    combined experienced recommended effected granted seen protected\n",
      "    adopted retarded notarized selected composed gotten printed ...\n",
      "VBD: verb, past tense\n",
      "    said produced took recommended commented urged found added praised\n",
      "    charged listed became announced brought attended wanted voted defeated\n",
      "    received got stood shot scheduled feared promised made ...\n",
      "CS: conjunction, subordinating\n",
      "    that as after whether before while like because if since for than altho\n",
      "    until so unless though providing once lest s'posin' till whereas\n",
      "    whereupon supposing tho' albeit then so's 'fore\n",
      "PPS: pronoun, personal, nominative, 3rd person singular\n",
      "    it he she thee\n",
      "VBG: verb, present participle or gerund\n",
      "    modernizing improving purchasing Purchasing lacking enabling pricing\n",
      "    keeping getting picking entering voting warning making strengthening\n",
      "    setting neighboring attending participating moving ...\n",
      "PP$: determiner, possessive\n",
      "    our its his their my your her out thy mine thine\n",
      "TO: infinitival to\n",
      "    to t'\n",
      "PPSS: pronoun, personal, nominative, not 3rd person singular\n",
      "    they we I you ye thou you'uns\n",
      "CD: numeral, cardinal\n",
      "    two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n",
      "    seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n",
      "    ...\n"
     ]
    }
   ],
   "source": [
    "for tag, _ in ft.most_common(20):\n",
    "    nltk.help.brown_tagset(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 4:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AT', 'JJ', 'IN', 'NN', 'PP$', 'CC', 'CD', 'AP', 'DT', 'VBG', ',', 'VBN', '.', 'NN-TL', 'JJ-TL', 'VB', 'NP', 'NP-TL', 'CS', 'NP$']"
     ]
    }
   ],
   "source": [
    "wtp = nltk.bigrams(brown.tagged_words())\n",
    "np = [a[1] for (a, b) in wtp if b[1].startswith('NN')]\n",
    "fd = nltk.FreqDist(np)\n",
    "prec_tags = [tag for (tag, _) in fd.most_common(20)]\n",
    "print(prec_tags, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT: article\n",
      "    the an no a every th' ever' ye\n",
      "JJ: adjective\n",
      "    ecent over-all possible hard-fought favorable hard meager fit such\n",
      "    widespread outmoded inadequate ambiguous grand clerical effective\n",
      "    orderly federal foster general proportionate ...\n",
      "IN: preposition\n",
      "    of in for by considering to on among at through with under into\n",
      "    regarding than since despite according per before toward against as\n",
      "    after during including between without except upon out over ...\n",
      "NN: noun, singular, common\n",
      "    failure burden court fire appointment awarding compensation Mayor\n",
      "    interim committee fact effect airport management surveillance jail\n",
      "    doctor intern extern night weekend duty legislation Tax Office ...\n",
      "PP$: determiner, possessive\n",
      "    our its his their my your her out thy mine thine\n",
      "CC: conjunction, coordinating\n",
      "    and or but plus & either neither nor yet 'n' and/or minus an'\n",
      "CD: numeral, cardinal\n",
      "    two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n",
      "    seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n",
      "    ...\n",
      "AP: determiner/pronoun, post-determiner\n",
      "    many other next more last former little several enough most least only\n",
      "    very few fewer past same Last latter less single plenty 'nough lesser\n",
      "    certain various manye next-to-last particular final previous present\n",
      "    nuf\n",
      "DT: determiner/pronoun, singular\n",
      "    this each another that 'nother\n",
      "VBG: verb, present participle or gerund\n",
      "    modernizing improving purchasing Purchasing lacking enabling pricing\n",
      "    keeping getting picking entering voting warning making strengthening\n",
      "    setting neighboring attending participating moving ...\n",
      ",: comma\n",
      "    ,\n",
      "VBN: verb, past participle\n",
      "    conducted charged won received studied revised operated accepted\n",
      "    combined experienced recommended effected granted seen protected\n",
      "    adopted retarded notarized selected composed gotten printed ...\n",
      ".: sentence terminator\n",
      "    . ? ; ! :\n",
      "No matching tags found.\n",
      "No matching tags found.\n",
      "VB: verb, base: uninflected present, imperative or infinitive\n",
      "    investigate find act follow inure achieve reduce take remedy re-set\n",
      "    distribute realize disable feel receive continue place protect\n",
      "    eliminate elaborate work permit run enter force ...\n",
      "NP: noun, singular, proper\n",
      "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
      "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
      "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
      "No matching tags found.\n",
      "CS: conjunction, subordinating\n",
      "    that as after whether before while like because if since for than altho\n",
      "    until so unless though providing once lest s'posin' till whereas\n",
      "    whereupon supposing tho' albeit then so's 'fore\n",
      "NP$: noun, singular, proper, genitive\n",
      "    Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n",
      "    Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n",
      "    Shea's Palmer's Arnold's Broglio's ...\n"
     ]
    }
   ],
   "source": [
    "for tag in prec_tags:\n",
    "    nltk.help.brown_tagset(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. \n",
    "\n",
    "◑ Explore the following issues that arise in connection with the lookup tagger:\n",
    "\n",
    "* a. What happens to the tagger performance for the various model sizes when a backoff tagger is omitted?\n",
    "\n",
    "* b. Consider the curve in [4.2](https://www.nltk.org/book/ch05.html#fig-tag-lookup); suggest a good size for a lookup tagger that balances memory and performance. Can you come up with scenarios where it would be preferable to minimize memory usage, or to maximize performance with no regard for memory usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
