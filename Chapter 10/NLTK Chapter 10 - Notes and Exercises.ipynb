{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 10\n",
    "\n",
    "## Analyzing the Meaning of Sentences\n",
    "\n",
    "*The html version of this chapter in the book is available [here](https://www.nltk.org/book/ch10.html \"ch10\").*\n",
    "\n",
    "### 1 Natural Language Understanding\n",
    "\n",
    "#### 1.1   Querying a Database\n",
    "\n",
    "The grammar used below allows us (in very limited situations) to convert a natural language query into SQL.  Unfortunately, the grammar no longer seems to be in the folder `book_grammars`, so I had to download the grammar from GitHub, which took a bit of tinkering to get to work:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT City FROM city_table WHERE Country=\"china\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import load_parser\n",
    "\n",
    "cp = nltk.parse.util.load_parser('https://raw.githubusercontent.com/nltk/nltk_teach/master/examples/grammars/book_grammars/sql0.fcfg')\n",
    "\n",
    "query = 'What cities are located in China'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn:__ Run the parser with maximum tracing on, i.e., `cp = load_parser('grammars/book_grammars/sql0.fcfg', trace=3)`, and examine how the values of `sem` are built up as complete edges are added to the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.W.c.a.l.i.C.|\n",
      "Leaf Init Rule:\n",
      "|[-] . . . . .| [0:1] 'What'\n",
      "|. [-] . . . .| [1:2] 'cities'\n",
      "|. . [-] . . .| [2:3] 'are'\n",
      "|. . . [-] . .| [3:4] 'located'\n",
      "|. . . . [-] .| [4:5] 'in'\n",
      "|. . . . . [-]| [5:6] 'China'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[-] . . . . .| [0:1] Det[SEM='SELECT'] -> 'What' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[-> . . . . .| [0:1] NP[SEM=(?det+?n)] -> Det[SEM=?det] * N[SEM=?n] {?det: 'SELECT'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. [-] . . . .| [1:2] N[SEM='City FROM city_table'] -> 'cities' *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[---] . . . .| [0:2] NP[SEM=(SELECT, City FROM city_table)] -> Det[SEM='SELECT'] N[SEM='City FROM city_table'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---> . . . .| [0:2] S[SEM=(?np+WHERE+?vp)] -> NP[SEM=?np] * VP[SEM=?vp] {?np: (SELECT, City FROM city_table)}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . [-] . . .| [2:3] IV[SEM=''] -> 'are' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . [-> . . .| [2:3] VP[SEM=(?v+?pp)] -> IV[SEM=?v] * PP[SEM=?pp] {?v: ''}\n",
      "|. . [-> . . .| [2:3] VP[SEM=(?v+?ap)] -> IV[SEM=?v] * AP[SEM=?ap] {?v: ''}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . [-] . .| [3:4] A[SEM=''] -> 'located' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . [-> . .| [3:4] AP[SEM=?pp] -> A[SEM=?a] * PP[SEM=?pp] {?a: ''}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . [-] .| [4:5] P[SEM=''] -> 'in' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . [-> .| [4:5] PP[SEM=(?p+?np)] -> P[SEM=?p] * NP[SEM=?np] {?p: ''}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . . [-]| [5:6] NP[SEM='Country=\"china\"'] -> 'China' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|. . . . . [->| [5:6] S[SEM=(?np+WHERE+?vp)] -> NP[SEM=?np] * VP[SEM=?vp] {?np: 'Country=\"china\"'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|. . . . [---]| [4:6] PP[SEM=(, Country=\"china\")] -> P[SEM=''] NP[SEM='Country=\"china\"'] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|. . . [-----]| [3:6] AP[SEM=(, Country=\"china\")] -> A[SEM=''] PP[SEM=(, Country=\"china\")] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|. . [-------]| [2:6] VP[SEM=(, , Country=\"china\")] -> IV[SEM=''] AP[SEM=(, Country=\"china\")] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[===========]| [0:6] S[SEM=(SELECT, City FROM city_table, WHERE, , , Country=\"china\")] -> NP[SEM=(SELECT, City FROM city_table)] VP[SEM=(, , Country=\"china\")] *\n",
      "SELECT City FROM city_table WHERE Country=\"china\"\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.parse.util.load_parser('https://raw.githubusercontent.com/nltk/nltk_teach/master/examples/grammars/book_grammars/sql0.fcfg', \n",
    "                                 trace = 3)\n",
    "\n",
    "query = 'What cities are located in China'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canton chungking dairen harbin kowloon mukden peking shanghai sian tientsin "
     ]
    }
   ],
   "source": [
    "from nltk.sem import chat80\n",
    "rows = chat80.sql_query('corpora/city_database/city.db', q)\n",
    "for r in rows: print(r[0], end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__: Extend the grammar `sql0.fcfg` so that it will translate [(4a)](https://www.nltk.org/book/ch10.html#ex-dbq21) into [(4b)](https://www.nltk.org/book/ch10.html#ex-dbq22), and check the values returned by the query.\n",
    "\n",
    "You will probably find it easiest to first extend the grammar to handle queries like *What cities have populations above 1,000,000* before tackling conjunction. After you have had a go at this task, you can compare your solution to `grammars/book_grammars/sql1.fcfg` in the NLTK data distribution.\n",
    "\n",
    "*Usually the __Your Turn__ exercises in this book are fairly trivial, but not this one.  My implementation didn't work until I peeked at the solution to find out what I was doing wrong.*\n",
    "\n",
    "*First, the code to make an SQL query from a natural language query looking for cities with more than 1,000,000 inhabitants:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT City FROM city_table WHERE Population > 1000\n"
     ]
    }
   ],
   "source": [
    "from nltk import grammar, parse\n",
    "\n",
    "g = \"\"\"\n",
    "% start S\n",
    "\n",
    "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
    "\n",
    "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
    "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
    "VP[SEM=(?v + ?np)] -> TV[SEM=?v] NP[SEM=?np]\n",
    "\n",
    "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
    "NP[SEM=(?n + ?pp)] -> N[SEM = ?n] PP[SEM=?pp]\n",
    "NP[SEM=?n] -> N[SEM=?n] | Num[SEM=?n]\n",
    "\n",
    "Num[SEM='1000'] -> '1,000,000'\n",
    "\n",
    "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
    "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
    "\n",
    "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
    "NP[SEM='Country=\"china\"'] -> 'China'\n",
    "\n",
    "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
    "\n",
    "N[SEM='City FROM city_table'] -> 'cities'\n",
    "N[SEM='Population'] -> 'populations'\n",
    "\n",
    "IV[SEM=''] -> 'are'\n",
    "TV[SEM=''] -> 'have'\n",
    "A[SEM=''] -> 'located'\n",
    "P[SEM=''] -> 'in' \n",
    "P[SEM='>'] -> 'above'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "gram = grammar.FeatureGrammar.fromstring(g)\n",
    "cp = parse.FeatureEarleyChartParser(gram)\n",
    "\n",
    "query = 'What cities have populations above 1,000,000'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to first query:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athens bangkok barcelona berlin birmingham bombay bucharest budapest buenos_aires cairo calcutta canton chicago chungking delhi detroit glasgow hamburg hongkong_city hyderabad istanbul karachi kyoto leningrad london los_angeles madras madrid manila melbourne mexico_city milan montreal moscow mukden nagoya nanking naples new_york osaka paris peking philadelphia rio_de_janeiro rome santiago sao_paulo seoul shanghai singapore_city sydney tehran tientsin tokyo vienna yokohama "
     ]
    }
   ],
   "source": [
    "from nltk.sem import chat80\n",
    "rows = chat80.sql_query('corpora/city_database/city.db', q)\n",
    "for r in rows: print(r[0], end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT City FROM city_table WHERE Country=\"china\" AND Population > 1000\n"
     ]
    }
   ],
   "source": [
    "from nltk import grammar, parse\n",
    "\n",
    "g = \"\"\"\n",
    "% start S\n",
    "\n",
    "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
    "\n",
    "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
    "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
    "VP[SEM=(?v + ?np)] -> TV[SEM=?v] NP[SEM=?np]\n",
    "VP[SEM=(?v1 + ?cc + ?v2)] -> VP[SEM=?v1] CC[SEM=?cc] VP[SEM=?v2]\n",
    "\n",
    "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
    "NP[SEM=(?n + ?pp)] -> N[SEM = ?n] PP[SEM=?pp]\n",
    "NP[SEM=?n] -> N[SEM=?n] | Num[SEM=?n]\n",
    "\n",
    "Num[SEM='1000'] -> '1,000,000'\n",
    "\n",
    "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
    "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
    "\n",
    "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
    "NP[SEM='Country=\"china\"'] -> 'China'\n",
    "\n",
    "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
    "\n",
    "N[SEM='City FROM city_table'] -> 'cities'\n",
    "N[SEM='Population'] -> 'populations'\n",
    "\n",
    "IV[SEM=''] -> 'are'\n",
    "TV[SEM=''] -> 'have'\n",
    "A[SEM=''] -> 'located'\n",
    "P[SEM=''] -> 'in' \n",
    "P[SEM='>'] -> 'above'\n",
    "CC[SEM='AND'] -> 'and'\n",
    "\"\"\"\n",
    "\n",
    "gram = grammar.FeatureGrammar.fromstring(g)\n",
    "cp = parse.FeatureEarleyChartParser(gram)\n",
    "\n",
    "query = 'What cities are in China and have populations above 1,000,000'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to second query.  Bear in mind this data is nearly 40 years old.  Now the answers would be much, much different:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canton chungking mukden peking shanghai tientsin "
     ]
    }
   ],
   "source": [
    "from nltk.sem import chat80\n",
    "rows = chat80.sql_query('corpora/city_database/city.db', q)\n",
    "for r in rows: print(r[0], end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2   Natural Language, Semantics and Logic\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "### 2   Propositional Logic\n",
    "\n",
    "Boolean operators in NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negation       \t-\n",
      "conjunction    \t&\n",
      "disjunction    \t|\n",
      "implication    \t->\n",
      "equivalence    \t<->\n"
     ]
    }
   ],
   "source": [
    "nltk.boolean_ops()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Table 2.1:__*\n",
    "\n",
    "Truth conditions for the Boolean Operators in Propositional Logic.\n",
    "\n",
    "\n",
    "|Boolean Operator |\t|Truth Conditions|\t\t|\n",
    "|:---\t|:---\t|:---:|:---|\n",
    "|negation (*it is not the case that…*)|\t-φ is true in $s$|\tiff\t|φ is false in $s$|\n",
    "|conjunction (*and*)|\t(φ & ψ) is true in $s$ |\tiff|\tφ is true in $s$ and ψ is true in $s$ |\n",
    "|disjunction (*or*)|\t(φ \\| ψ) is true in $s$ |\tiff|\tφ is true in $s$ or ψ is true in $s$ |\n",
    "|implication (*if ..., then …*)|\t(φ -> ψ) is true in $s$ |\tiff|\tφ is false in $s$ or ψ is true in $s$ |\n",
    "|equivalence (*if and only if*)|\t(φ <-> ψ) is true in $s$|\tiff|\tφ and ψ are both true in $s$ or both false in $s$|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these rules are straightforward, with the exception of *implication*.  An implication of the form (`P -> Q`) is only false when `P` is true and `Q` is false.  Thus, a formula where `P` corresponds to 'Elvis is still alive and is working at a Wal-Mart in Arkansas' and `Q` corresponds to 'Thursday comes after Wednesday' would come out true.\n",
    "\n",
    "NLTK's `Expression` object can process logical expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NegatedExpression -(P & Q)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "read_expr('-(P & Q)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AndExpression (P & Q)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr('P & Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OrExpression (P | (R -> Q))>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr('P | (R -> Q)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IffExpression (P <-> --P)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr('P <-> -- P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLTK, a third-party application called Prover9 can test theorems, but this needs to be downloaded separately and I can't seem to find anyone who's currently hosting the file, so I'm skipping the next section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paused at \"Recall that we interpret sentences of a logical language relative to a model, which is a very simplified version of the world....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
