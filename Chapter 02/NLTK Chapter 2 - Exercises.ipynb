{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 1\n",
    "\n",
    "## Accessing Text Corpora and Lexical Resources\n",
    "\n",
    "*The html version of this chapter in the NLTK book is available [here](https://www.nltk.org/book/ch02.html#exercises \"Ch02 Exercises\").*\n",
    "\n",
    "### 8   Exercises\n",
    "\n",
    "###### 1. \n",
    "\n",
    "☼ Create a variable `phrase` containing a list of words. Review the operations described in the previous chapter, including addition, multiplication, indexing, slicing, and sorting.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase1 = ['This', 'is', 'a', 'lovely', 'list', 'of', 'words.']\n",
    "phrase2 = ['As', 'is', 'this.']\n",
    "\n",
    "phrase1 + phrase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'lovely', 'list', 'of', 'words.', 'This', 'is', 'a', 'lovely', 'list', 'of', 'words.', 'This', 'is', 'a', 'lovely', 'list', 'of', 'words.']"
     ]
    }
   ],
   "source": [
    "print(phrase1 * 3, end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'words.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'lovely', 'list', 'of', 'words.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase1[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As', 'This', 'a', 'is', 'is', 'list', 'lovely', 'of', 'this.', 'words.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(phrase1 + phrase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.\n",
    "\n",
    "☼ Use the corpus module to explore `austen-persuasion.txt`. How many word tokens does this book have? How many word types?\n",
    "\n",
    "*As I discussed at length in my notes, I recommend removing non-alphabetic characters and enclitics:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83617"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "austen = 'austen-persuasion.txt'\n",
    "enclitics = (\"d\", \"ll\", \"m\", \"re\", \"s\", \"t\", \"ve\")\n",
    "words = gutenberg.words(austen)\n",
    "\n",
    "# number of tokens\n",
    "num_tokens = len([w for w in words if w.isalpha() and w not in enclitics])\n",
    "\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of word types\n",
    "num_wt = len(set([w for w in words if w.isalpha() and w not in enclitics]))\n",
    "num_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we didn't bother with removing non-alphabetic characters and enclitics:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98171"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tokens\n",
    "num_tokens = len([w for w in words])\n",
    "\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6132"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of word types\n",
    "num_wt = len(set([w for w in words]))\n",
    "num_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. \n",
    "\n",
    "☼ Use the Brown corpus reader `nltk.corpus.brown.words()` or the Web text corpus reader `nltk.corpus.webtext.words()` to access some sample text in two different genres.\n",
    "\n",
    "*The code below will randomly choose a category, and then randomly print five sentences from that category.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['or', 'allowing', 'survival', 'of', 'a', 'dividend', 'carryover', 'to', 'a', 'personal', 'holding', 'company', '(', 'section', '381(c)(14)', ')', ',', 'but', 'not', 'carryover', 'of', 'excess', 'tax', 'credits', 'for', 'foreign', 'taxes', '?', '?'], ['These', 'items', ',', 'and', 'most', 'of', 'the', 'others', 'listed', 'above', ',', 'seem', 'quite', 'comparable', 'to', 'items', 'whose', 'right', 'of', 'survival', 'is', 'provided', 'for', 'in', 'section', '381', '.'], ['There', 'does', 'not', 'seem', 'to', 'be', 'any', 'reasonable', 'basis', 'for', 'distinction', 'either', 'in', 'terms', 'of', 'the', 'nature', 'of', 'the', 'tax', 'attribute', 'or', 'in', 'terms', 'of', 'tax-avoidance', 'possibilities', '.'], ['With', 'respect', 'to', 'items', 'such', 'as', 'these', 'the', 'provisions', 'of', 'section', '381(c)', ',', 'viewed', 'in', 'historical', 'perspective', ',', 'suggest', 'a', 'rule', 'requiring', 'survival', ',', 'whether', 'the', 'items', 'are', 'beneficial', 'or', 'detrimental', 'to', 'the', 'surviving', 'corporation', '.'], ['To', 'this', 'extent', 'some', 'stretching', 'of', 'the', 'literal', 'meaning', 'of', 'the', 'Committee', 'Report', 'seems', 'justified', ',', 'since', 'the', 'literal', 'meaning', 'conflicts', 'with', 'the', 'clear', 'implication', ',', 'if', 'not', 'the', 'language', ',', 'of', 'the', 'statute', '.']]"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import random\n",
    "\n",
    "random_category = random.choice(brown.categories())\n",
    "random_place = random.randint(0, len(brown.sents(categories = random_category)) - 5)\n",
    "\n",
    "\n",
    "print(brown.sents(categories = random_category)[random_place:random_place + 5], end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As you can see, the output doesn't look very nice.  We could try a list comprehension:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['or', 'allowing', 'survival', 'of', 'a', 'dividend', 'carryover', 'to', 'a', 'personal', 'holding', 'company', '(', 'section', '381(c)(14)', ')', ',', 'but', 'not', 'carryover', 'of', 'excess', 'tax', 'credits', 'for', 'foreign', 'taxes', '?', '?'], ['These', 'items', ',', 'and', 'most', 'of', 'the', 'others', 'listed', 'above', ',', 'seem', 'quite', 'comparable', 'to', 'items', 'whose', 'right', 'of', 'survival', 'is', 'provided', 'for', 'in', 'section', '381', '.'], ['There', 'does', 'not', 'seem', 'to', 'be', 'any', 'reasonable', 'basis', 'for', 'distinction', 'either', 'in', 'terms', 'of', 'the', 'nature', 'of', 'the', 'tax', 'attribute', 'or', 'in', 'terms', 'of', 'tax-avoidance', 'possibilities', '.'], ['With', 'respect', 'to', 'items', 'such', 'as', 'these', 'the', 'provisions', 'of', 'section', '381(c)', ',', 'viewed', 'in', 'historical', 'perspective', ',', 'suggest', 'a', 'rule', 'requiring', 'survival', ',', 'whether', 'the', 'items', 'are', 'beneficial', 'or', 'detrimental', 'to', 'the', 'surviving', 'corporation', '.'], ['To', 'this', 'extent', 'some', 'stretching', 'of', 'the', 'literal', 'meaning', 'of', 'the', 'Committee', 'Report', 'seems', 'justified', ',', 'since', 'the', 'literal', 'meaning', 'conflicts', 'with', 'the', 'clear', 'implication', ',', 'if', 'not', 'the', 'language', ',', 'of', 'the', 'statute', '.']]"
     ]
    }
   ],
   "source": [
    "print([w for w in brown.sents(categories = random_category)[random_place:random_place + 5]], end = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*That doesn't help much.  I seem to recall having this problem in Chapter 1, so I believe I'll place the code I used into a function:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_text(l):\n",
    "    full_sent = \"\"\n",
    "    alpha_text = []\n",
    "\n",
    "    for i in range(len(l)):\n",
    "\n",
    "        ## TO DO: find a more general solution for intra-word punctuation\n",
    "        if l[i].isalpha() or '-' in l[i]:\n",
    "            alpha_text.append(l[i])\n",
    "        else:\n",
    "            full_sent += (' '.join(alpha_text) + l[i] + ' ')\n",
    "            alpha_text = []\n",
    "\n",
    "    return full_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or allowing survival of a dividend carryover to a personal holding company( section381(c)(14) ) , but not carryover of excess tax credits for foreign taxes? ? These items, and most of the others listed above, seem quite comparable to items whose right of survival is provided for in section381 . There does not seem to be any reasonable basis for distinction either in terms of the nature of the tax attribute or in terms of tax-avoidance possibilities. With respect to items such as these the provisions of section381(c) , viewed in historical perspective, suggest a rule requiring survival, whether the items are beneficial or detrimental to the surviving corporation. To this extent some stretching of the literal meaning of the Committee Report seems justified, since the literal meaning conflicts with the clear implication, if not the language, of the statute. \n"
     ]
    }
   ],
   "source": [
    "text = [w for w in brown.sents(categories = random_category)[random_place:random_place + 5]]\n",
    "\n",
    "full_text = []\n",
    "for t in text:\n",
    "    full_text.append(convert_list_to_text(t))\n",
    "print(''.join(full_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It's not perfect, but it looks much better than it did.  Let's try it again with another random text:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But he was not. So what? ? Why should I be spinning just because the goddamn log is spinning? ? ( he asked this out loud, but no one heard it over the other noise in the hut) . Over on the bank, the west bank, a man stood, calling to him. \n"
     ]
    }
   ],
   "source": [
    "random_category = random.choice(brown.categories())\n",
    "random_place = random.randint(0, len(brown.sents(categories = random_category)) - 5)\n",
    "\n",
    "text = [w for w in brown.sents(categories = random_category)[random_place:random_place + 5]]\n",
    "\n",
    "full_text = []\n",
    "for t in text:\n",
    "    full_text.append(convert_list_to_text(t))\n",
    "print(''.join(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
