{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 9\n",
    "\n",
    "## Building Feature Based Grammars\n",
    "\n",
    "*The html version of this chapter in the book is available [here](https://www.nltk.org/book/ch09.html \"ch09\").*\n",
    "\n",
    "### 1   Grammatical Features\n",
    "\n",
    "We're now going to declare the features of words and phrases.  Here's an example of using dictionaries to store features and their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim = {'CAT': 'NP', 'ORTH': 'Kim', 'REF': 'k'}\n",
    "chase = {'CAT': 'V', 'ORTH': 'chased', 'REL': 'chase'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature structures__ are the pairings of features and values.\n",
    "\n",
    "Adding more properties to the verb *chase*.  The subject plays the role of \"agent\" and the object the role of \"patient\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase['AGT'] = 'sbj'\n",
    "chase['PAT'] = 'obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rather convoluted code that follows processes the sentence *Kim chased Lee* and \"binds\" the verb's agent role to the subject (because it's to the left of the verb) and patient role to the object (because it's to the right of the verb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "sent = \"Kim chased Lee\"\n",
    "tokens = sent.split()\n",
    "lee = {'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}\n",
    "\n",
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            return fs\n",
    "        \n",
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])\n",
    "verb['AGT'] = subj['REF']\n",
    "verb['PAT'] = obj['REF']\n",
    "\n",
    "for k in ['ORTH', 'REL', 'AGT', 'PAT']:\n",
    "    print(\"%-5s => %s\" % (k, verb[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1   Syntactic Agreement\n",
    "\n",
    "This simple grammar would permit *This dog runs*, but it would also permit sentences where the noun and verb don't agree, such as <i>*Theses dogs runs<i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "simple_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Det N \n",
    "VP -> V\n",
    "Det -> 'this' | 'these'\n",
    "N -> 'dog' | 'dogs'\n",
    "V -> 'runs'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This more complex grammar would block sentences without agreement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP_SG VP_SG\n",
    "S -> NP_PL VP_PL\n",
    "NP_SG -> Det_SG N_SG\n",
    "NP_PL -> Det_PL N_PL\n",
    "VP_SG -> V_SG\n",
    "VP_PL -> V_PL\n",
    "\n",
    "Det_SG -> 'this'\n",
    "Det_PL -> 'these'\n",
    "N_SG -> 'dog'\n",
    "N_PL -> 'dogs'\n",
    "V_SG -> 'runs'\n",
    "V_PL -> 'run'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In effect, we've doubled the size of our grammar.  If we needed agreement for first, second and thrid person as well, this method would result in a grammar that would be six times the size of our original `simple` grammar.  We will look at ways of streamlining this.\n",
    "\n",
    "#### 1.2 Using Attributes and Constraints\n",
    "\n",
    "We could add __features__ to our notation, and use variables over values to reduce the number of required productions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "S[NUM = ?n] -> NP[NUM = ?n] VP[NUM = ?n]\n",
    "NP[NUM = ?n] -> Det[NUM = ?n] N[NUM = ?n]\n",
    "VP[NUM = ?n] -> V[NUM = ?n]\n",
    "Det[NUM = sg] -> 'this'\n",
    "Det[NUM = pl] -> 'these'\n",
    "N[NUM = sg] -> 'dog'\n",
    "N[NUM = pl] -> 'dogs'\n",
    "V[NUM = sg] -> 'runs'\n",
    "V[NUM = pl] -> 'run'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, there has to be agreement now, or the parse will fail.  \n",
    "\n",
    "For words that agree with all numbers (i.e., singular and plural), we can leave the `NUM` value __underspecified__ instead of declaring it twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "S[NUM = ?n] -> NP[NUM = ?n] VP[NUM = ?n]\n",
    "NP[NUM = ?n] -> Det[NUM = ?n] N[NUM = ?n]\n",
    "VP[NUM = ?n] -> V[NUM = ?n]\n",
    "\n",
    "Det[NUM = sg] -> 'this'\n",
    "Det[NUM = pl] -> 'these'\n",
    "N[NUM = sg] -> 'dog'\n",
    "N[NUM = pl] -> 'dogs'\n",
    "V[NUM = sg] -> 'runs'\n",
    "V[NUM = pl] -> 'run'\n",
    "Det[NUM = ?n] -> 'the' | 'some' | 'any'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ideas from this chapter - and a few more - can be found in the grammar below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this grammar with a parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'Kim likes children'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/feat0.fcfg', trace = 2)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3   Terminology\n",
    "\n",
    "Values like `sg` and `pl` are __atomic__ because they can't be decomposed into subparts.  We can use a __boolean__ value to distinguish __auxiliary__ verbs (e.g., modal verbs) with the boolean feature `AUX`.  For example, *can* could be represented with the production `V[TENSE=pres, AUX=+]`, though the convention is to put the `+/-` sign in front of the feature, like so: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "V[TENSE=pres, +AUX] -> 'can'\n",
    "V[TENSE=pres, +AUX] -> 'may'\n",
    "\n",
    "V[TENSE=pres, -AUX] -> 'walks'\n",
    "V[TENSE=pres, -AUX] -> 'likes'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also group together the features in an __attribute value matrix__ (AVM):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[POS = N           ]\n",
    "[                  ]\n",
    "[AGR = [PER = 3   ]]\n",
    "[      [NUM = pl  ]]\n",
    "[      [GND = fem ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order does not matter in representation, so this would be equivalent:\n",
    "\n",
    "```\n",
    "[AGR = [NUM = pl  ]]\n",
    "[      [PER = 3   ]]\n",
    "[      [GND = fem ]]\n",
    "[                  ]\n",
    "[POS = N           ]\n",
    "```\n",
    "\n",
    "We could then refactor a grammar so that agreement features are bundled together like so:\n",
    "\n",
    "```S                    -> NP[AGR=?n] VP[AGR=?n]\n",
    "NP[AGR=?n]           -> PropN[AGR=?n]\n",
    "VP[TENSE=?t, AGR=?n] -> Cop[TENSE=?t, AGR=?n] Adj\n",
    "\n",
    "Cop[TENSE=pres,  AGR=[NUM=sg, PER=3]] -> 'is'\n",
    "PropN[AGR=[NUM=sg, PER=3]]            -> 'Kim'\n",
    "Adj                                   -> 'happy'\n",
    "```\n",
    "\n",
    "### 2   Processing Feature Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
