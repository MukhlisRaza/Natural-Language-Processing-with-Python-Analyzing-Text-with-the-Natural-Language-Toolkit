{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 4\n",
    "\n",
    "## Writing Structured Programs\n",
    "\n",
    "*The html version of this chapter is available [here](https://www.nltk.org/book/ch04.html \"ch04\").*\n",
    "\n",
    "### 4.1 Back to the Basics\n",
    "\n",
    "#### Assignment\n",
    "\n",
    "*__Your Turn__: Use multiplication to create a list of lists: `nested = [[]] * 3`. Now modify one of the elements of the list, and observe that all the elements are changed. Use Python's `id()` function to find out the numerical identifier for any object, and verify that `id(nested[0])`, `id(nested[1])`, and `id(nested[2])` are all the same.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested = [[]] * 3\n",
    "[id(nested[i]) == id(nested[j]) for i, j  in zip([0, 0, 1], [1, 2, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__N.B.:__ To copy a structure w/o copying the object references, use `copy.deepcopy()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test = [1, 2, 3]\n",
    "test2 = copy.deepcopy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['foo', 2, 3] [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "test[0] = 'foo'\n",
    "\n",
    "print(test, test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equality\n",
    "\n",
    "*Objects can have the same value (verifiable by `==`), but have different references (verifiable by `is`):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "python = ['Python']\n",
    "snake_nest = [python] * size\n",
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "position = random.choice(range(size))\n",
    "snake_nest[position] = ['Python']\n",
    "snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use `id` to see which object has a different reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1739372726600, 1739372726600, 1739387617480, 1739372726600, 1739372726600]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditionals\n",
    "\n",
    "*Empty strings or lists are also evaluated as false:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    "mixed = ['cat', '', ['dog'], []]\n",
    "\n",
    "for element in mixed:\n",
    "    if element:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sequences\n",
    "\n",
    "#### Operating on Sequence Types\n",
    "\n",
    "| Python Expression                  | Comment                                 |\n",
    "|:-----------------------------------|:----------------------------------------|\n",
    "| `for item in s`                    | iterate over the items of `s`           |\n",
    "| `for item in sorted(s)`            | iterate over the items of `s` in order  |\n",
    "| `for item in set(s)`               | iterate over unique elements of `s`     |\n",
    "| `for item in reversed(s)`          | iterate over elements of `s` in reverse |\n",
    "| `for item in set(s).difference(t)` | iterate over elements of `s` not in `t` |\n",
    "|                                    |                                         |\n",
    "|                                    |                                         |\n",
    "|                                    |                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Other objects (e.g., a `FreqDist`) can be converted into a sequence, from where we can use iteration.  E.g.:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'Red', 'lorry', 'red', 'yellow']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "sorted(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: 1; lorry: 4; ,: 3; yellow: 2; red: 1; .: 1; "
     ]
    }
   ],
   "source": [
    "for key in fdist:\n",
    "    print(key + ':', fdist[key], end = '; ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using tuples to re-arrange the contents of our list:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "words[2], words[3], words[4] = words[3], words[4], words[2]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Examples of `zip` and `enumerate`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x19480fd7788>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'noun'), ('turned', 'verb'), ('off', 'prep'), ('the', 'det'), ('spectroroute', 'noun')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(words, tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Another example: Dividing a set into training and test sets:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.nps_chat.words()\n",
    "cut = int(0.9 * len(text))\n",
    "training_data, test_data = text[:cut], text[cut:]\n",
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Different Sequence Types\n",
    "\n",
    "*We can use the above methods together to sort the words in a string by length.  The `_` is a convention for a variable whose values won't be used:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'I turned off the spectroroute'.split()\n",
    "wordlens = [(len(word), word) for word in words]\n",
    "wordlens.sort()\n",
    "' '.join(w for (_, w) in wordlens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__N.B.:__ In tuples the ordering is very important, as operations (e.g., sorting) are performed on the first item in the tuple.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Your Turn:__ Convert `lexicon` to a tuple, using `lexicon = tuple(lexicon)`, then try each of the above operations, to confirm that none of them is permitted on tuples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('the', 'det', ['Di:', 'D@']), ('off', 'prep', ['Qf', 'O:f']))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = [\n",
    "    ('the', 'det', ['Di:', 'D@']),\n",
    "    ('off', 'prep', ['Qf', 'O:f'])\n",
    "]\n",
    "lexicon = tuple(lexicon)\n",
    "lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`sort` won't work.  As with earlier chapters, I'm not going to include non-functioning code in the notebook cells, and will instead include it as markdown:*\n",
    "\n",
    "```\n",
    "lexicon.sort()\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-43-f0ef1dd8cf20> in <module>\n",
    "----> 1 lexicon.sort()\n",
    "\n",
    "AttributeError: 'tuple' object has no attribute 'sort'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ditto with item assignment:*\n",
    "\n",
    "```\n",
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-44-e4e3a95fe95b> in <module>\n",
    "----> 1 lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    "\n",
    "TypeError: 'tuple' object does not support item assignment\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*And also item deletion:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "del lexicon[0]\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-45-0ba66aa11bf3> in <module>\n",
    "----> 1 del lexicon[0]\n",
    "\n",
    "TypeError: 'tuple' object doesn't support item deletion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Expressions\n",
    "\n",
    "*Example of tokenizing and normalizing a text:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'when', 'i', 'use', 'a', 'word', ',', \"''\", 'humpty', 'dumpty', 'said', 'in', 'rather', 'a', 'scornful', 'tone', ',', '``', 'it', 'means', 'just', 'what', 'i', 'choose', 'it', 'to', 'mean', '-', 'neither', 'more', 'nor', 'less', '.', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone,\n",
    "          \"it means just what I choose it to mean - neither more nor less.\"'''\n",
    "print([w.lower() for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In the two following expressions, the second one is faster, especially if the text is very large:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([w.lower() for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(w.lower() for w in word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Questions of Style\n",
    "\n",
    "#### Python Coding Style\n",
    "\n",
    "*Coding style guide is [here](https://www.python.org/dev/peps/pep-0008/ \"style guide\").*\n",
    "\n",
    "#### Procedural vs. Declarative Style\n",
    "\n",
    "*The examples are too long to copy.  The upshot: __Procedural style__ is very close to machine language - not very concise.  __Declarative style__ is higher level, with operations happening behid the scenes.  Declarative style often uses list comprehensions and is faster; but procedural style may be easier to understand and debug.\n",
    "\n",
    "#### Some Legitimate Uses for Counters\n",
    "\n",
    "*We could use a nested list comprehension to build a $m$ by $n$ array:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), {'Alice'}, set()]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "m, n = 3, 7\n",
    "array = [[set() for i in range(n)] for j in range(m)]\n",
    "array[2][5].add('Alice')\n",
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This would not work with multiplication:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}]]\n"
     ]
    }
   ],
   "source": [
    "array = [[set()] * n] * m\n",
    "array[2][5].add(7)\n",
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Functions: The Foundation of Structured Programming\n",
    "\n",
    "#### Function Inputs and Outputs\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "#### Parameter Passing\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "#### Variable Scope\n",
    "\n",
    "*Because careful using the `global` declaration.*\n",
    "\n",
    "#### Checking Parameter Types\n",
    "\n",
    "*Use `assert isinstance(var, type), \"warning\"` to deal with incorrect parameter types being passed to a function.*\n",
    "\n",
    "#### Functional Decomposition\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "#### Documenting Functions\n",
    "\n",
    "*Cf. [here](http://www.python.org/dev/peps/pep-0257/ \"docstring conventions\") for more information on docstring conventions.*\n",
    "\n",
    "*NLTK uses Sphinx markup language to document parameters.  Sphinx can be automatically converted into API documentation.  I __have__ seen this used, but I wouldn't really say that it's that common.  For shits and giggles, I'll copy and paste a function from the book that uses Sphinx:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Doing More with Functions\n",
    "\n",
    "#### Functions as Arguments\n",
    "\n",
    "*I found this section to be really poorly written.  For one thing, it uses a function - `extract_property` - that will only work on one specific list.  If this isn't an example of a bad function, I don't know what is, and I find it especially vexing that this is in a chapter dedicated to writing efficient and logical code.*\n",
    "\n",
    "*Another problem I have is that it very cursorily introduces __lambda  expressions__, which need a much more thorough explanation.*\n",
    "\n",
    "*Finally, the example in this section uses `cmp()`, which has been removed from Python 3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accumulative Functions\n",
    "\n",
    "*Here are two examples of accumulative functions.  The second is more efficient, since it uses a generator:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search1(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            result.append(word)\n",
    "    return result\n",
    "    \n",
    "def search2(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza \n",
      "\n",
      "Elapsed time is: 2.42352032661438\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for item in search1('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end = \" \")\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n\\nElapsed time is:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza \n",
      "\n",
      "Elapsed time is: 2.691038131713867\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for item in search2('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end = \" \")\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n\\nElapsed time is:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Although the second function was supposed to be more efficient, it actually takes slightly more time to run.*\n",
    "\n",
    "*Here's an example of a recurisve function.  Recursive functions are more difficult to follow, and this one is no exception.  I'm also not sure why they introduced recursive functions here when they make no effort to explain what they are or how they work.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutations(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "    else:\n",
    "        for perm in permutations(seq[1:]):\n",
    "            for i in range(len(perm) + 1):\n",
    "                yield perm[:i] + seq[0:1] + perm[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['police', 'fish', 'buffalo'],\n",
       " ['fish', 'police', 'buffalo'],\n",
       " ['fish', 'buffalo', 'police'],\n",
       " ['police', 'buffalo', 'fish'],\n",
       " ['buffalo', 'police', 'fish'],\n",
       " ['buffalo', 'fish', 'police']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(permutations(['police', 'fish', 'buffalo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher-Order Functions\n",
    "\n",
    "*`filter` applies a function and only returns items whose value is `True`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_content_word(word):\n",
    "    return word.lower() not in ['a', 'of', 'the', 'and', 'will', ',', '.']\n",
    "\n",
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "        'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']\n",
    "\n",
    "list(filter(is_content_word, sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This would be the corresponding list comprehension:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent if is_content_word(w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`map` applies a function to every item in a sequence:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = list(map(len, nltk.corpus.brown.sents(categories = 'news')))\n",
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The corresponding list comprehension:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(sent) for sent in nltk.corpus.brown.sents(categories = 'news')]\n",
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here are two examples where we count the number of vowels in each word in `sent`.  Note that the line comprehension is much easier to follow than the lambda expression.  Also note that I had to add `list` - which was missing in the book - to get this to work:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 3, 0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda w: len(list(filter(lambda c: c.lower() in \"aeiou\", w))), sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 1, 2, 0, 1, 1, 2, 1, 2, 2, 1, 3, 0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(list(c for c in w if c.lower() in \"aeiou\")) for w in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Arguments\n",
    "\n",
    "<i>__Keyword arguments__ are arguments that are defined when we call the function, using syntax like this: `sample_function(new_arg = \"this value\")`.  They are usually abbreviated as `kwargs` inside functions, as opposed to `args`. The `*` before `args` means the number of possible arguments is not specified - i.e., we can use as many arguments as we'd like.  The corresponding syntax for keyword arguments is `**kwargs`:</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'African swallow')\n",
      "{'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    "def generic(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "    \n",
    "generic(1, \"African swallow\", monty = \"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Program Development\n",
    "\n",
    "#### Structure of a Python Module\n",
    "\n",
    "*To find the location of a file on the hard drive, add `__file__` to the file's name.  __N.B.:__ The example used in the book - `nltk.metrics.distance.__file__` can not seem to be found, but by navigating through the folders I was able to find it.  Not sure why it's not turning up when I try to call it from the jupyter notebook...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mjcor\\\\Anaconda3\\\\lib\\\\site-packages\\\\nltk\\\\translate\\\\metrics.py'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.metrics.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\mjcor\\Anaconda3\\lib\\site-packages\\nltk\\translate\\metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__N.B.:__ variables and functions only used within a certain module have names beginning with an underscore.  If another module imports the module in question, these variables and functions will not be imported.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Module Programs\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "#### Sources of Error\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "#### Debugging Techniques\n",
    "\n",
    "*Python has a __debugger__ (`pdb`) which can help us monitor what's happening inside a program.*\n",
    "\n",
    "*Below is an example of a function that has some behavior which is most likely unwanted:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(text, wordlength, result = []):\n",
    "    for word in text:\n",
    "        if len(word) == wordlength:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "find_words(['cat'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`pdb` generates a prompt, meaning that I'll have difficulties when I later run all the cells in this notebook, so I'll run it once now and include the traceback as markdown.*\n",
    "\n",
    "*Commands with `pdb`:*\n",
    "\n",
    " *`help`: full list of commands\n",
    "\n",
    " *`step` (or just `s`): will execute the current line and stop. \n",
    "If the current line calls a function, it will enter the function and stop at the first line. \n",
    "\n",
    " *`next` (or just `n`): is similar, but it stops execution at the next line in the current function. \n",
    "\n",
    " *`break` (or `b`): can be used to create or list breakpoints. \n",
    "\n",
    " *`continue` (or `c`): continue execution as far as the next breakpoint. \n",
    "\n",
    "Type the name of any variable to inspect its value.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "pdb.run(\"find_words(['dog'], 3)\")\n",
    "\n",
    "> <string>(1)<module>()\n",
    "(Pdb) s\n",
    "--Call--\n",
    "> <ipython-input-108-fd1321c8447a>(1)find_words()\n",
    "-> def find_words(text, wordlength, result = []):\n",
    "(Pdb) s\n",
    "> <ipython-input-108-fd1321c8447a>(2)find_words()\n",
    "-> for word in text:\n",
    "(Pdb) s\n",
    "> <ipython-input-108-fd1321c8447a>(3)find_words()\n",
    "-> if len(word) == wordlength:\n",
    "(Pdb) s\n",
    "> <ipython-input-108-fd1321c8447a>(4)find_words()\n",
    "-> result.append(word)\n",
    "(Pdb) s\n",
    "> <ipython-input-108-fd1321c8447a>(2)find_words()\n",
    "-> for word in text:\n",
    "(Pdb) s\n",
    "> <ipython-input-108-fd1321c8447a>(5)find_words()\n",
    "-> return result\n",
    "(Pdb) s\n",
    "--Return--\n",
    "> <ipython-input-108-fd1321c8447a>(5)find_words()->['cat', 'dog']\n",
    "-> return result\n",
    "(Pdb) s\n",
    "--Return--\n",
    "> <string>(1)<module>()->None\n",
    "(Pdb) s\n",
    "> c:\\users\\mjcor\\anaconda3\\lib\\bdb.py(589)run()\n",
    "-> self.quitting = True\n",
    "(Pdb) s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defensive Programming\n",
    "\n",
    "*__Regression testing__ is using a suite of test cases to detect situations where a change to the code has an unintended side-effect of breaking something.  The [`doctest` documentation](http://docs.python.org/library/doctest.html \"doctest\") has more information.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Algorithm Design\n",
    "\n",
    "#### Recursion\n",
    "\n",
    "*Here's a recursive program to determine the size of a WordNet hyponym hierarchy (the book says 'hypernym', but examining the code shows that it's clearly the 'hyponym' hierarchy that's being investigated):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def size1(s):\n",
    "    return 1 + sum(size1(child) for child in s.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "size1(dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here is an iterative program that does the same thing.  The authors attest that the recursive is easier to interpret, but I feel this is a matter of opinion.  And as the authors mention a bit later, recursion in python is usually slower than iteration.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size2(s):\n",
    "    layer = [s]\n",
    "    total = 0\n",
    "    while layer:\n",
    "        total += len(layer)\n",
    "        layer = [h for c in layer for h in c.hyponyms()]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "size2(dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here's another example of a recursion: a program that builds a __letter trie__:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "\n",
    "trie = dict(trie)\n",
    "\n",
    "trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(trie, width = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
